{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version is good\n",
      "Region = eu-central-1\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "# from sagemaker.image_uris import retrieve\n",
    "from sagemaker.s3 import *\n",
    "import sys\n",
    "import subprocess\n",
    "import os\n",
    "\n",
    "if int(sagemaker.__version__.split('.')[0]) == 2:\n",
    "    !{sys.executable} -m pip install sagemaker==1.72.0\n",
    "    print(\"Installing previous SageMaker Version. Please restart the kernel\")\n",
    "else:\n",
    "    print(\"Version is good\")\n",
    "\n",
    "role = get_execution_role()\n",
    "\n",
    "\n",
    "sess = sagemaker.Session(default_bucket=None)\n",
    "region = boto3.session.Session().region_name\n",
    "print(\"Region = {}\".format(region))\n",
    "\n",
    "sm = boto3.Session().client('sagemaker')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing image:  763104351884.dkr.ecr.eu-central-1.amazonaws.com/pytorch-training:1.6.0-cpu-py36-ubuntu16.04\n",
      "Training image:  763104351884.dkr.ecr.eu-central-1.amazonaws.com/pytorch-training:1.6.0-gpu-py36-cu110-ubuntu16.04\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# see https://sagemaker.readthedocs.io/en/stable/api/utility/image_uris.html for which inputs to use\n",
    "# see https://github.com/aws/deep-learning-containers/blob/master/available_images.md for registry paths with custom algorithms\n",
    "prefix = \"763104351884.dkr.ecr.eu-central-1.amazonaws.com/pytorch-training\"\n",
    "PREPROCESSING_IMAGE = \"{}:{}\".format(prefix, \"1.6.0-cpu-py36-ubuntu16.04\")\n",
    "PREPROCESS_INSTANCE = \"ml.m5.xlarge\"\n",
    "\n",
    "\n",
    "TRAINING_IMAGE = \"{}:{}\".format(prefix, \"1.6.0-gpu-py36-cu110-ubuntu16.04\")\n",
    "TRAINING_INSTANCE = \"ml.g4dn.xlarge\" \n",
    "\n",
    "print (\"Preprocessing image: \", PREPROCESSING_IMAGE)\n",
    "print (\"Training image: \", TRAINING_IMAGE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sagemaker-experiments\n",
      "  Using cached sagemaker_experiments-0.1.25-py3-none-any.whl (40 kB)\n",
      "Requirement already satisfied: boto3>=1.16.27 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from sagemaker-experiments) (1.16.37)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from boto3>=1.16.27->sagemaker-experiments) (0.10.0)\n",
      "Requirement already satisfied: botocore<1.20.0,>=1.19.37 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from boto3>=1.16.27->sagemaker-experiments) (1.19.37)\n",
      "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from boto3>=1.16.27->sagemaker-experiments) (0.3.3)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from boto3>=1.16.27->sagemaker-experiments) (0.10.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from botocore<1.20.0,>=1.19.37->boto3>=1.16.27->sagemaker-experiments) (1.25.11)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from botocore<1.20.0,>=1.19.37->boto3>=1.16.27->sagemaker-experiments) (2.8.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.20.0,>=1.19.37->boto3>=1.16.27->sagemaker-experiments) (1.15.0)\n",
      "Requirement already satisfied: botocore<1.20.0,>=1.19.37 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from boto3>=1.16.27->sagemaker-experiments) (1.19.37)\n",
      "Installing collected packages: sagemaker-experiments\n",
      "Successfully installed sagemaker-experiments-0.1.25\n",
      "\u001b[33mWARNING: You are using pip version 20.3; however, version 20.3.3 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/pytorch_p36/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install sagemaker-experiments \n",
    "from sagemaker.analytics import ExperimentAnalytics\n",
    "from smexperiments.experiment import Experiment\n",
    "from smexperiments.trial import Trial\n",
    "from smexperiments.trial_component import TrialComponent\n",
    "from smexperiments.tracker import Tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_local_bucket = sess.default_bucket() # Alternatively you can use our custom bucket here. \n",
    "original_data_bucket = \"treetracker-training-images\"\n",
    "prefix = 'sagemaker-modelmonitor' # use this prefix to store all files pertaining to this workshop.\n",
    "\n",
    "dataprefix = prefix + '/data'\n",
    "traindataprefix = prefix + '/train_data'\n",
    "testdataprefix = prefix + '/test_data'\n",
    "testdatanolabelprefix = prefix + '/test_data_no_label'\n",
    "trainheaderprefix = prefix + '/train_headers'\n",
    "\n",
    "dataset_key = \"imnet\" # use this to restrict to a particular directory\n",
    "train_key = \"train\"\n",
    "validation_key = \"validation\"\n",
    "test_key = \"test\"\n",
    "s3_raw = 's3://{}/{}/'.format(original_data_bucket, dataset_key)\n",
    "sagemaker_train = 's3://{}/{}/'.format(sagemaker_local_bucket, train_key)\n",
    "sagemaker_validation = 's3://{}/{}/'.format(sagemaker_local_bucket, validation_key)\n",
    "sagemaker_test = 's3://{}/{}/'.format(sagemaker_local_bucket, test_key)\n",
    "\n",
    "os.environ[\"SAGEMAKER_VALIDATION\"] = sagemaker_validation\n",
    "os.environ[\"SAGEMAKER_TRAIN\"] = sagemaker_train\n",
    "os.environ[\"SAGEMAKER_TEST\"] = sagemaker_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 rm $SAGEMAKER_VALIDATION --recursive --quiet\n",
    "!aws s3 rm $SAGEMAKER_TRAIN --recursive --quiet\n",
    "!aws s3 rm $SAGEMAKER_TEST --recursive --quiet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Figure out preprocessing instance jobs\n",
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "from sagemaker.processing import ScriptProcessor\n",
    "\n",
    "pre_input = [ProcessingInput(source=s3_raw, destination=\"/opt/ml/processing/raw/\", input_name=\"raw\")]\n",
    "pre_output = [ProcessingOutput(source=\"/opt/ml/processing/train/\", destination=sagemaker_train),\n",
    "              ProcessingOutput(source=\"/opt/ml/processing/validation/\", destination=sagemaker_validation),\n",
    "              ProcessingOutput(source=\"/opt/ml/processing/test/\", destination=sagemaker_test)]\n",
    "            \n",
    "              \n",
    "script_processor = ScriptProcessor(command= [\"python\"], \n",
    "                                    image_uri=PREPROCESSING_IMAGE,\n",
    "                                    role=role,\n",
    "                                    instance_count=1,\n",
    "                                    instance_type=PREPROCESS_INSTANCE,\n",
    "                                    base_job_name=\"preprocessing-test\", \n",
    "                                    max_runtime_in_seconds=7200)\n",
    "\n",
    "preprocessing_script = \"preprocessing_p1.py\" # Put path to preprocessing script here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sagemaker:Parameter 'session' will be renamed to 'sagemaker_session' in SageMaker Python SDK v2.\n",
      "INFO:sagemaker:Creating processing-job with name preprocessing-test-2021-01-07-04-21-43-954\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Job Name:  preprocessing-test-2021-01-07-04-21-43-954\n",
      "Inputs:  [{'InputName': 'raw', 'S3Input': {'S3Uri': 's3://treetracker-training-images/imnet/', 'LocalPath': '/opt/ml/processing/raw/', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}, {'InputName': 'code', 'S3Input': {'S3Uri': 's3://sagemaker-eu-central-1-053061259712/preprocessing-test-2021-01-07-04-21-43-954/input/code/preprocessing_p1.py', 'LocalPath': '/opt/ml/processing/input/code', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}]\n",
      "Outputs:  [{'OutputName': 'output-1', 'S3Output': {'S3Uri': 's3://sagemaker-eu-central-1-053061259712/train/', 'LocalPath': '/opt/ml/processing/train/', 'S3UploadMode': 'EndOfJob'}}, {'OutputName': 'output-2', 'S3Output': {'S3Uri': 's3://sagemaker-eu-central-1-053061259712/validation/', 'LocalPath': '/opt/ml/processing/validation/', 'S3UploadMode': 'EndOfJob'}}, {'OutputName': 'output-3', 'S3Output': {'S3Uri': 's3://sagemaker-eu-central-1-053061259712/test/', 'LocalPath': '/opt/ml/processing/test/', 'S3UploadMode': 'EndOfJob'}}]\n",
      "..........................................................................\u001b[34mSkipping class desk\u001b[0m\n",
      "\u001b[34mImg paths preview: \n",
      "                class  ...                                    annotation_path\u001b[0m\n",
      "\u001b[34mn12513613_1258  judas  ...  /opt/ml/processing/raw/bounding_boxes/judas/An...\u001b[0m\n",
      "\u001b[34mn12513613_794   judas  ...                                               None\u001b[0m\n",
      "\u001b[34mn12513613_8545  judas  ...                                               None\u001b[0m\n",
      "\u001b[34mn12513613_9474  judas  ...                                               None\u001b[0m\n",
      "\u001b[34mn12513613_455   judas  ...                                               None\n",
      "\u001b[0m\n",
      "\u001b[34m[5 rows x 5 columns]\u001b[0m\n",
      "\u001b[34mTotal num images:  41883\u001b[0m\n",
      "\u001b[34mNum annotated images:  7958\u001b[0m\n",
      "\u001b[34mNum tree images:  41883\u001b[0m\n",
      "\u001b[34mProcessing class  judas\u001b[0m\n",
      "\u001b[34mProcessing class  palm\u001b[0m\n",
      "\u001b[34mProcessing class  pine\u001b[0m\n",
      "\u001b[34mProcessing class  china tree\u001b[0m\n",
      "\u001b[34mProcessing class  fig\u001b[0m\n",
      "\u001b[34mProcessing class  cabbage\u001b[0m\n",
      "\u001b[34mProcessing class  cacao\u001b[0m\n",
      "\u001b[34mProcessing class  kapok\u001b[0m\n",
      "\u001b[34mProcessing class  iron\u001b[0m\n",
      "\u001b[34mProcessing class  linden\u001b[0m\n",
      "\u001b[34mProcessing class  pepper\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.6/site-packages/PIL/TiffImagePlugin.py:788: UserWarning: Corrupt EXIF data.  Expecting to read 2 bytes but only got 0. \n",
      "  warnings.warn(str(msg))\u001b[0m\n",
      "\u001b[34mProcessing class  rain\u001b[0m\n",
      "\u001b[34mProcessing class  dita\u001b[0m\n",
      "\u001b[34mProcessing class  alder\u001b[0m\n",
      "\u001b[34mProcessing class  silk\u001b[0m\n",
      "\u001b[34mProcessing class  coral\u001b[0m\n",
      "\u001b[34mProcessing class  huisache\u001b[0m\n",
      "\u001b[34mProcessing class  fringe\u001b[0m\n",
      "\u001b[34mProcessing class  dogwood\u001b[0m\n",
      "\u001b[34mProcessing class  cork\u001b[0m\n",
      "\u001b[34mProcessing class  ginkgo\u001b[0m\n",
      "\u001b[34mProcessing class  golden shower\u001b[0m\n",
      "\u001b[34mProcessing class  balata\u001b[0m\n",
      "\u001b[34mProcessing class  baobab\u001b[0m\n",
      "\u001b[34mProcessing class  sorrel\u001b[0m\n",
      "\u001b[34mProcessing class  Japanese pagoda\u001b[0m\n",
      "\u001b[34mProcessing class  Kentucky coffee\u001b[0m\n",
      "\u001b[34mProcessing class  Logwood\u001b[0m\n",
      "\u001b[34mProcessing class  garbage_bin\u001b[0m\n",
      "\u001b[34mProcessing class  carion_fungus\u001b[0m\n",
      "\u001b[34mProcessing class  basidiomycetous_fungus\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.6/site-packages/PIL/TiffImagePlugin.py:788: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 0. \n",
      "  warnings.warn(str(msg))\u001b[0m\n",
      "\u001b[34mProcessing class  jelly_fungus\u001b[0m\n",
      "\u001b[34mProcessing class  desktop_computer\u001b[0m\n",
      "\u001b[34mProcessing class  laptop_computer\u001b[0m\n",
      "\u001b[34mProcessing class  cellphone\u001b[0m\n",
      "\u001b[34mProcessing class  desk\u001b[0m\n",
      "\u001b[34mProcessing class  station_wagon\u001b[0m\n",
      "\u001b[34mProcessing class  pickup_truck\u001b[0m\n",
      "\u001b[34mProcessing class  trailer_truck\u001b[0m\n",
      "\u001b[34mProcessing class  judas\u001b[0m\n",
      "\u001b[34mProcessing class  palm\u001b[0m\n",
      "\u001b[34mProcessing class  pine\u001b[0m\n",
      "\u001b[34mProcessing class  china tree\u001b[0m\n",
      "\u001b[34mProcessing class  fig\u001b[0m\n",
      "\u001b[34mProcessing class  cabbage\u001b[0m\n",
      "\u001b[34mProcessing class  cacao\u001b[0m\n",
      "\u001b[34mProcessing class  kapok\u001b[0m\n",
      "\u001b[34mProcessing class  iron\u001b[0m\n",
      "\u001b[34mProcessing class  linden\u001b[0m\n",
      "\u001b[34mProcessing class  pepper\u001b[0m\n",
      "\u001b[34mProcessing class  rain\u001b[0m\n",
      "\u001b[34mProcessing class  dita\u001b[0m\n",
      "\u001b[34mProcessing class  alder\u001b[0m\n",
      "\u001b[34mProcessing class  silk\u001b[0m\n",
      "\u001b[34mProcessing class  coral\u001b[0m\n",
      "\u001b[34mProcessing class  huisache\u001b[0m\n",
      "\u001b[34mProcessing class  fringe\u001b[0m\n",
      "\u001b[34mProcessing class  dogwood\u001b[0m\n",
      "\u001b[34mProcessing class  cork\u001b[0m\n",
      "\u001b[34mProcessing class  ginkgo\u001b[0m\n",
      "\u001b[34mProcessing class  golden shower\u001b[0m\n",
      "\u001b[34mProcessing class  balata\u001b[0m\n",
      "\u001b[34mProcessing class  baobab\u001b[0m\n",
      "\u001b[34mProcessing class  sorrel\u001b[0m\n",
      "\u001b[34mProcessing class  Japanese pagoda\u001b[0m\n",
      "\u001b[34mProcessing class  Kentucky coffee\u001b[0m\n",
      "\u001b[34mProcessing class  Logwood\u001b[0m\n",
      "\u001b[34mProcessing class  garbage_bin\u001b[0m\n",
      "\u001b[34mProcessing class  carion_fungus\u001b[0m\n",
      "\u001b[34mProcessing class  basidiomycetous_fungus\u001b[0m\n",
      "\u001b[34mProcessing class  jelly_fungus\u001b[0m\n",
      "\u001b[34mProcessing class  desktop_computer\u001b[0m\n",
      "\u001b[34mProcessing class  laptop_computer\u001b[0m\n",
      "\u001b[34mProcessing class  cellphone\u001b[0m\n",
      "\u001b[34mProcessing class  desk\u001b[0m\n",
      "\u001b[34mProcessing class  station_wagon\u001b[0m\n",
      "\u001b[34mProcessing class  pickup_truck\u001b[0m\n",
      "\u001b[34mProcessing class  trailer_truck\u001b[0m\n",
      "\u001b[34mProcessing class  judas\u001b[0m\n",
      "\u001b[34mProcessing class  palm\u001b[0m\n",
      "\u001b[34mProcessing class  pine\u001b[0m\n",
      "\u001b[34mProcessing class  china tree\u001b[0m\n",
      "\u001b[34mProcessing class  fig\u001b[0m\n",
      "\u001b[34mProcessing class  cabbage\u001b[0m\n",
      "\u001b[34mProcessing class  cacao\u001b[0m\n",
      "\u001b[34mProcessing class  kapok\u001b[0m\n",
      "\u001b[34mProcessing class  iron\u001b[0m\n",
      "\u001b[34mProcessing class  linden\u001b[0m\n",
      "\u001b[34mProcessing class  pepper\u001b[0m\n",
      "\u001b[34mProcessing class  rain\u001b[0m\n",
      "\u001b[34mProcessing class  dita\u001b[0m\n",
      "\u001b[34mProcessing class  alder\u001b[0m\n",
      "\u001b[34mProcessing class  silk\u001b[0m\n",
      "\u001b[34mProcessing class  coral\u001b[0m\n",
      "\u001b[34mProcessing class  huisache\u001b[0m\n",
      "\u001b[34mProcessing class  fringe\u001b[0m\n",
      "\u001b[34mProcessing class  dogwood\u001b[0m\n",
      "\u001b[34mProcessing class  cork\u001b[0m\n",
      "\u001b[34mProcessing class  ginkgo\u001b[0m\n",
      "\u001b[34mProcessing class  golden shower\u001b[0m\n",
      "\u001b[34mProcessing class  balata\u001b[0m\n",
      "\u001b[34mProcessing class  baobab\u001b[0m\n",
      "\u001b[34mProcessing class  sorrel\u001b[0m\n",
      "\u001b[34mProcessing class  Japanese pagoda\u001b[0m\n",
      "\u001b[34mProcessing class  Kentucky coffee\u001b[0m\n",
      "\u001b[34mProcessing class  Logwood\u001b[0m\n",
      "\u001b[34mProcessing class  garbage_bin\u001b[0m\n",
      "\u001b[34mProcessing class  carion_fungus\u001b[0m\n",
      "\u001b[34mProcessing class  basidiomycetous_fungus\u001b[0m\n",
      "\u001b[34mProcessing class  jelly_fungus\u001b[0m\n",
      "\u001b[34mProcessing class  desktop_computer\u001b[0m\n",
      "\u001b[34mProcessing class  laptop_computer\u001b[0m\n",
      "\u001b[34mProcessing class  cellphone\u001b[0m\n",
      "\u001b[34mProcessing class  desk\u001b[0m\n",
      "\u001b[34mProcessing class  station_wagon\u001b[0m\n",
      "\u001b[34mProcessing class  pickup_truck\u001b[0m\n",
      "\u001b[34mProcessing class  trailer_truck\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "script_processor.run(preprocessing_script, \n",
    "                    inputs=pre_input,\n",
    "                    outputs=pre_output,\n",
    "                    arguments=None)\n",
    "\n",
    "# default arguments in script should work for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO: Add step for RecordIO format "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "# This is where you can add hyperparameters, framework used, point to the script, and define instances you want to train on. \n",
    "# ALl of this information is represented as environment variables passed to the instance. In your script, you can refer to these variables or \n",
    "# the argument. \n",
    "\n",
    "# TODO: add metric monitoring via CloudWatch \n",
    "# https://docs.aws.amazon.com/sagemaker/latest/dg/training-metrics.html\n",
    "estimator = PyTorch(entry_point='mobilenet_v2.py',\n",
    "                    role=role,\n",
    "                    framework_version='1.6.0',\n",
    "                    train_instance_count=1,\n",
    "                    train_instance_type=TRAINING_INSTANCE,\n",
    "                    hyperparameters={\n",
    "                        'epochs': 5,\n",
    "                        'backend': 'gloo',\n",
    "                        'train_split': 0.7, \n",
    "                        'log_interval': 200\n",
    "                    },                   \n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sagemaker:'create_image_uri' will be deprecated in favor of 'ImageURIProvider' class in SageMaker Python SDK v2.\n",
      "WARNING:sagemaker:'s3_input' class will be renamed to 'TrainingInput' in SageMaker Python SDK v2.\n",
      "WARNING:sagemaker:'s3_input' class will be renamed to 'TrainingInput' in SageMaker Python SDK v2.\n",
      "WARNING:sagemaker:'s3_input' class will be renamed to 'TrainingInput' in SageMaker Python SDK v2.\n",
      "WARNING:sagemaker:'create_image_uri' will be deprecated in favor of 'ImageURIProvider' class in SageMaker Python SDK v2.\n",
      "INFO:sagemaker:Creating training-job with name: pytorch-training-2021-01-08-03-59-32-173\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-01-08 03:59:32 Starting - Starting the training job...\n",
      "2021-01-08 03:59:34 Starting - Launching requested ML instances......\n",
      "2021-01-08 04:00:38 Starting - Preparing the instances for training...\n",
      "2021-01-08 04:01:21 Downloading - Downloading input data.............................................\n",
      "2021-01-08 04:08:56 Training - Downloading the training image..\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2021-01-08 04:09:11,355 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2021-01-08 04:09:11,375 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2021-01-08 04:09:11,381 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2021-01-08 04:09:11,829 sagemaker-training-toolkit INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"test\": \"/opt/ml/input/data/test\",\n",
      "        \"training\": \"/opt/ml/input/data/training\",\n",
      "        \"validation\": \"/opt/ml/input/data/validation\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"train_split\": 0.7,\n",
      "        \"backend\": \"gloo\",\n",
      "        \"log_interval\": 200,\n",
      "        \"epochs\": 5\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"test\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"training\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"validation\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"pytorch-training-2021-01-08-03-59-32-173\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-eu-central-1-053061259712/pytorch-training-2021-01-08-03-59-32-173/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"mobilenet_v2\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 1,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"mobilenet_v2.py\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"backend\":\"gloo\",\"epochs\":5,\"log_interval\":200,\"train_split\":0.7}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=mobilenet_v2.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"validation\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"test\",\"training\",\"validation\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=mobilenet_v2\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-eu-central-1-053061259712/pytorch-training-2021-01-08-03-59-32-173/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"test\":\"/opt/ml/input/data/test\",\"training\":\"/opt/ml/input/data/training\",\"validation\":\"/opt/ml/input/data/validation\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"backend\":\"gloo\",\"epochs\":5,\"log_interval\":200,\"train_split\":0.7},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"validation\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"pytorch-training-2021-01-08-03-59-32-173\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-eu-central-1-053061259712/pytorch-training-2021-01-08-03-59-32-173/source/sourcedir.tar.gz\",\"module_name\":\"mobilenet_v2\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":1,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"mobilenet_v2.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--backend\",\"gloo\",\"--epochs\",\"5\",\"--log_interval\",\"200\",\"--train_split\",\"0.7\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TEST=/opt/ml/input/data/test\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAINING=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_VALIDATION=/opt/ml/input/data/validation\u001b[0m\n",
      "\u001b[34mSM_HP_TRAIN_SPLIT=0.7\u001b[0m\n",
      "\u001b[34mSM_HP_BACKEND=gloo\u001b[0m\n",
      "\u001b[34mSM_HP_LOG_INTERVAL=200\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=5\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python36.zip:/opt/conda/lib/python3.6:/opt/conda/lib/python3.6/lib-dynload:/opt/conda/lib/python3.6/site-packages\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python mobilenet_v2.py --backend gloo --epochs 5 --log_interval 200 --train_split 0.7\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34mDidn't find labels for 441 images in /opt/ml/input/data/training\u001b[0m\n",
      "\u001b[34mShuffled label preview\n",
      "                       class bbox  is_tree\u001b[0m\n",
      "\u001b[34mn12317296_11039         iron  NaN     True\u001b[0m\n",
      "\u001b[34mn11757851_28526     huisache  NaN     True\u001b[0m\n",
      "\u001b[34mn02747177_15723  garbage_bin  NaN    False\u001b[0m\n",
      "\u001b[34mn12242409_4085        sorrel  NaN     True\u001b[0m\n",
      "\u001b[34mn11608250_5701          pine  NaN     True\u001b[0m\n",
      "\u001b[34m(25110, 3)\u001b[0m\n",
      "\u001b[34mDidn't find labels for 0 images in /opt/ml/input/data/validation\u001b[0m\n",
      "\u001b[34mShuffled label preview\n",
      "                           class                  bbox  is_tree\u001b[0m\n",
      "\u001b[34mn12478768_4826           cabbage                   NaN     True\u001b[0m\n",
      "\u001b[34mn03642806_12643  laptop_computer                   NaN    False\u001b[0m\n",
      "\u001b[34mn02992529_6586         cellphone  (231, 144, 351, 300)    False\u001b[0m\n",
      "\u001b[34mn02992529_466          cellphone                   NaN    False\u001b[0m\n",
      "\u001b[34mn12765115_14445           pepper                   NaN     True\u001b[0m\n",
      "\u001b[34m(8382, 3)\u001b[0m\n",
      "\u001b[34mDistributed training - False\u001b[0m\n",
      "\u001b[34mNumber of gpus available - 1\u001b[0m\n",
      "\u001b[34mStarting at epoch 0\u001b[0m\n",
      "\u001b[34m==================================================\u001b[0m\n",
      "\u001b[34mEPOCH 1\u001b[0m\n",
      "\u001b[34m2021-01-08 04:09:18,426 sagemaker-training-toolkit ERROR    ExecuteUserScriptError:\u001b[0m\n",
      "\u001b[34mCommand \"/opt/conda/bin/python mobilenet_v2.py --backend gloo --epochs 5 --log_interval 200 --train_split 0.7\"\u001b[0m\n",
      "\u001b[34mDownloading: \"https://download.pytorch.org/models/mobilenet_v2-b0353104.pth\" to /root/.cache/torch/hub/checkpoints/mobilenet_v2-b0353104.pth\u001b[0m\n",
      "\u001b[34m#015  0%|          | 0.00/13.6M [00:00<?, ?B/s]#015100%|ââââââââââ| 13.6M/13.6M [00:00<00:00, 152MB/s]\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.6/site-packages/torch/cuda/__init__.py:125: UserWarning: \u001b[0m\n",
      "\u001b[34mTesla T4 with CUDA capability sm_75 is not compatible with the current PyTorch installation.\u001b[0m\n",
      "\u001b[34mThe current PyTorch install supports CUDA capabilities sm_35 sm_52 sm_60 sm_61 sm_70 compute_70.\u001b[0m\n",
      "\u001b[34mIf you want to use the Tesla T4 GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/\n",
      "\n",
      "  warnings.warn(incompatible_device_warn.format(device_name, capability, \" \".join(arch_list), device_name))\u001b[0m\n",
      "\u001b[34mTraceback (most recent call last):\n",
      "  File \"mobilenet_v2.py\", line 429, in <module>\n",
      "    trainer.train(args)\n",
      "  File \"mobilenet_v2.py\", line 274, in train\n",
      "    for batchx, batchy in self.data_loader:\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 363, in __next__\n",
      "    data = self._next_data()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 403, in _next_data\n",
      "    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py\", line 47, in fetch\n",
      "    return self.collate_fn(data)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/torch/utils/data/_utils/collate.py\", line 84, in default_collate\n",
      "    return [default_collate(samples) for samples in transposed]\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/torch/utils/data/_utils/collate.py\", line 84, in <listcomp>\n",
      "    return [default_collate(samples) for samples in transposed]\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/torch/utils/data/_utils/collate.py\", line 74, in default_collate\n",
      "    return {key: default_collate([d[key] for d in batch]) for key in elem}\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/torch/utils/data/_utils/collate.py\", line 74, in <dictcomp>\n",
      "    return {key: default_collate([d[key] for d in batch]) for key in elem}\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/torch/utils/data/_utils/collate.py\", line 68, in default_collate\n",
      "    return torch.tensor(batch, dtype=torch.float64)\u001b[0m\n",
      "\u001b[34mTypeError: must be real number, not str\u001b[0m\n",
      "\n",
      "2021-01-08 04:09:21 Uploading - Uploading generated training model\n",
      "2021-01-08 04:10:10 Failed - Training job failed\n"
     ]
    },
    {
     "ename": "UnexpectedStatusException",
     "evalue": "Error for Training job pytorch-training-2021-01-08-03-59-32-173: Failed. Reason: AlgorithmError: ExecuteUserScriptError:\nCommand \"/opt/conda/bin/python mobilenet_v2.py --backend gloo --epochs 5 --log_interval 200 --train_split 0.7\"\nDownloading: \"https://download.pytorch.org/models/mobilenet_v2-b0353104.pth\" to /root/.cache/torch/hub/checkpoints/mobilenet_v2-b0353104.pth\n\r  0%|          | 0.00/13.6M [00:00<?, ?B/s]\r100%|ââââââââââ| 13.6M/13.6M [00:00<00:00, 152MB/s]\n/opt/conda/lib/python3.6/site-packages/torch/cuda/__init__.py:125: UserWarning: \nTesla T4 with CUDA capability sm_75 is not compatible with the current PyTorch installation.\nThe current PyTorch install supports CUDA capabilities sm_35 sm_52 sm_60 sm_61 sm_70 compute_70.\nIf you want to use the Tesla T4 GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/\n\n  warnings.warn(incompatible_device_warn.format(device_name, capability, \" \".join(arch_list), device_name))\nTraceback (most recent call last):\n  File \"mobilenet_v2.py\", line 429, in <module>\n    trainer.train(args)\n  Fi",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnexpectedStatusException\u001b[0m                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-4674df5db690>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"training\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msagemaker_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"validation\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msagemaker_validation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"test\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msagemaker_test\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/sagemaker/estimator.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, inputs, wait, logs, job_name, experiment_config)\u001b[0m\n\u001b[1;32m    497\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_training_job\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 499\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_training_job\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    500\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_compilation_job_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/sagemaker/estimator.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, logs)\u001b[0m\n\u001b[1;32m   1137\u001b[0m         \u001b[0;31m# If logs are requested, call logs_for_jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1138\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlogs\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"None\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1139\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogs_for_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1140\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_for_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36mlogs_for_job\u001b[0;34m(self, job_name, wait, poll, log_type)\u001b[0m\n\u001b[1;32m   3075\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3076\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3077\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_job_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescription\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"TrainingJobStatus\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3078\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdot\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3079\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36m_check_job_status\u001b[0;34m(self, job, desc, status_key_name)\u001b[0m\n\u001b[1;32m   2669\u001b[0m                 ),\n\u001b[1;32m   2670\u001b[0m                 \u001b[0mallowed_statuses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Completed\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Stopped\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2671\u001b[0;31m                 \u001b[0mactual_status\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2672\u001b[0m             )\n\u001b[1;32m   2673\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnexpectedStatusException\u001b[0m: Error for Training job pytorch-training-2021-01-08-03-59-32-173: Failed. Reason: AlgorithmError: ExecuteUserScriptError:\nCommand \"/opt/conda/bin/python mobilenet_v2.py --backend gloo --epochs 5 --log_interval 200 --train_split 0.7\"\nDownloading: \"https://download.pytorch.org/models/mobilenet_v2-b0353104.pth\" to /root/.cache/torch/hub/checkpoints/mobilenet_v2-b0353104.pth\n\r  0%|          | 0.00/13.6M [00:00<?, ?B/s]\r100%|ââââââââââ| 13.6M/13.6M [00:00<00:00, 152MB/s]\n/opt/conda/lib/python3.6/site-packages/torch/cuda/__init__.py:125: UserWarning: \nTesla T4 with CUDA capability sm_75 is not compatible with the current PyTorch installation.\nThe current PyTorch install supports CUDA capabilities sm_35 sm_52 sm_60 sm_61 sm_70 compute_70.\nIf you want to use the Tesla T4 GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/\n\n  warnings.warn(incompatible_device_warn.format(device_name, capability, \" \".join(arch_list), device_name))\nTraceback (most recent call last):\n  File \"mobilenet_v2.py\", line 429, in <module>\n    trainer.train(args)\n  Fi"
     ]
    }
   ],
   "source": [
    " estimator.fit({\"training\": sagemaker_train, \"validation\": sagemaker_validation, \"test\": sagemaker_test})"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "conda_amazonei_mxnet_p27",
   "language": "python",
   "name": "conda_amazonei_mxnet_p27"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
